# Ollama 설정
OLLAMA_BASE_URL=http://localhost:11434

# 사용할 모델 (llama3.1, mistral, qwen2.5 등)
OLLAMA_MODEL=llama3.1

# 임베딩 모델 (nomic-embed-text, mxbai-embed-large 등)
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
